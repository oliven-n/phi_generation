{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# now we need an appropriate way to split\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# what if the split is at a specific place that we dont want\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# that's why overlap\u001b[39;00m\n\u001b[32m     14\u001b[39m text_splitter = RecursiveCharacterTextSplitter(\n\u001b[32m     15\u001b[39m     chunk_size=\u001b[32m1000\u001b[39m,\n\u001b[32m     16\u001b[39m     chunk_overlap=\u001b[32m500\u001b[39m,\n\u001b[32m     17\u001b[39m     length_function=\u001b[38;5;28mlen\u001b[39m,\n\u001b[32m     18\u001b[39m     add_start_index=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     19\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m chunks=text_splitter.split_documents(\u001b[43mdocuments\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'code_files\\rag_module\\data'\n",
    "\n",
    "# loads the source material (when markdown)\n",
    "#each markdown file becomes a document (has contents and metadata like the name)\n",
    "# perhaps we want to add metadata like \"reference material\"!! \n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.md\")\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# now we need an appropriate way to split\n",
    "# what if the split is at a specific place that we dont want\n",
    "# that's why overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=500,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: you're going to need to figure out how to get the user to set their API key. Perhaps this goes in the tutorial, etc. \n",
    "It has been coded in here for your (short-term) convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 3 documents into 0 chunks.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHROMA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mgenerate_data_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mgenerate_data_store\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_data_store\u001b[39m():\n\u001b[32m     29\u001b[39m     documents = load_documents()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     chunks = \u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     save_to_chroma(chunks)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36msplit_text\u001b[39m\u001b[34m(documents)\u001b[39m\n\u001b[32m     47\u001b[39m chunks = text_splitter.split_documents(documents)\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSplit \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m document = \u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(document.page_content)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(document.metadata)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# # from langchain.document_loaders import DirectoryLoader\n",
    "# from langchain_community.document_loaders import DirectoryLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.schema import Document\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "# #from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# import openai \n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Load environment variables. Assumes that project contains .env file with API keys\n",
    "# load_dotenv()\n",
    "# #---- Set OpenAI API key \n",
    "# # Change environment variable name from \"OPENAI_API_KEY\" to the name given in \n",
    "# # your .env file.\n",
    "# #openai.api_key = os.environ['']\n",
    "# openai.api_key= ''\n",
    "# DATA_PATH = \"data\"\n",
    "# CHROMA_PATH = \"chroma\"\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     generate_data_store()\n",
    "\n",
    "\n",
    "# def generate_data_store():\n",
    "#     documents = load_documents()\n",
    "#     chunks = split_text(documents)\n",
    "#     save_to_chroma(chunks)\n",
    "\n",
    "\n",
    "# def load_documents():\n",
    "#     loader = DirectoryLoader(DATA_PATH, glob=\"*.md\")\n",
    "#     documents = loader.load()\n",
    "#     return documents\n",
    "\n",
    "\n",
    "# def split_text(documents: list[Document]):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         chunk_size=1000,\n",
    "#         chunk_overlap=500,\n",
    "#         length_function=len,\n",
    "#         add_start_index=True,\n",
    "#     )\n",
    "#     chunks = text_splitter.split_documents(documents)\n",
    "#     print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "#     document = chunks[10]\n",
    "#     print(document.page_content)\n",
    "#     print(document.metadata)\n",
    "\n",
    "#     return chunks\n",
    "\n",
    "\n",
    "# def save_to_chroma(chunks: list[Document]):\n",
    "#     # Clear out the database first.\n",
    "#     if os.path.exists(CHROMA_PATH):\n",
    "#         shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "#     # Create a new DB from the documents.\n",
    "#     db = Chroma.from_documents(\n",
    "#         chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n",
    "#     )\n",
    "#     db.persist()\n",
    "#     print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the debugging version of the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MAIN ---\n",
      "\n",
      "--- GENERATE_DATA_STORE ---\n",
      "\n",
      "--- LOAD_DOCUMENTS ---\n",
      "Loaded 0 documents.\n",
      "\n",
      "--- SPLIT_TEXT ---\n",
      "Split 0 documents into 0 chunks.\n",
      "chunks list does not have 11 elements\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected Embeddings to be non-empty list or numpy array, got [] in upsert.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:409\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;129m@validation_context\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mupsert\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_and_prepare_upsert_request\u001b[39m(\n\u001b[32m    395\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    407\u001b[39m ) -> UpsertRequest:\n\u001b[32m    408\u001b[39m     \u001b[38;5;66;03m# Unpack\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     upsert_records = \u001b[43mnormalize_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\types.py:208\u001b[39m, in \u001b[36mnormalize_insert_record_set\u001b[39m\u001b[34m(ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03mUnpacks and normalizes the fields of an InsertRecordSet.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m base_record_set = \u001b[43mnormalize_base_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InsertRecordSet(\n\u001b[32m    213\u001b[39m     ids=cast(IDs, maybe_cast_one_to_many(ids)),\n\u001b[32m    214\u001b[39m     metadatas=maybe_cast_one_to_many(metadatas),\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m     uris=base_record_set[\u001b[33m\"\u001b[39m\u001b[33muris\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    219\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\types.py:185\u001b[39m, in \u001b[36mnormalize_base_record_set\u001b[39m\u001b[34m(embeddings, documents, images, uris)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03mUnpacks and normalizes the fields of a BaseRecordSet.\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseRecordSet(\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     embeddings=\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    186\u001b[39m     documents=maybe_cast_one_to_many(documents),\n\u001b[32m    187\u001b[39m     images=maybe_cast_one_to_many(images),\n\u001b[32m    188\u001b[39m     uris=maybe_cast_one_to_many(uris),\n\u001b[32m    189\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\types.py:82\u001b[39m, in \u001b[36mnormalize_embeddings\u001b[39m\u001b[34m(target)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     83\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected Embeddings to be non-empty list or numpy array, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m     )\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# One PyEmbedding\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Expected Embeddings to be non-empty list or numpy array, got []",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m     generate_data_store()\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- MAIN ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[43mgenerate_data_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mgenerate_data_store\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     62\u001b[39m documents = load_documents()\n\u001b[32m     63\u001b[39m chunks = split_text(documents)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43msave_to_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36msave_to_chroma\u001b[39m\u001b[34m(chunks)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_to_chroma\u001b[39m(chunks):\n\u001b[32m     54\u001b[39m     embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     vector_store = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCHROMA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     vector_store.persist()\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- SAVE_TO_CHROMA ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m    838\u001b[39m         api=chroma_collection._client,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    839\u001b[39m         ids=ids,\n\u001b[32m    840\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    841\u001b[39m         documents=texts,\n\u001b[32m    842\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:326\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m         \u001b[38;5;28mself\u001b[39m._collection.upsert(\n\u001b[32m    321\u001b[39m             embeddings=embeddings_without_metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    322\u001b[39m             documents=texts_without_metadatas,\n\u001b[32m    323\u001b[39m             ids=ids_without_metadatas,\n\u001b[32m    324\u001b[39m         )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:336\u001b[39m, in \u001b[36mCollection.upsert\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupsert\u001b[39m(\n\u001b[32m    312\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    313\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    324\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    325\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[32m    326\u001b[39m \n\u001b[32m    327\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    334\u001b[39m \u001b[33;03m        None\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     upsert_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._upsert(\n\u001b[32m    346\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    347\u001b[39m         ids=upsert_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    354\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:98\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg).with_traceback(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:409\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;129m@validation_context\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mupsert\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_and_prepare_upsert_request\u001b[39m(\n\u001b[32m    395\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    407\u001b[39m ) -> UpsertRequest:\n\u001b[32m    408\u001b[39m     \u001b[38;5;66;03m# Unpack\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     upsert_records = \u001b[43mnormalize_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m    419\u001b[39m     validate_insert_record_set(record_set=upsert_records)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\types.py:208\u001b[39m, in \u001b[36mnormalize_insert_record_set\u001b[39m\u001b[34m(ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize_insert_record_set\u001b[39m(\n\u001b[32m    193\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m    194\u001b[39m     embeddings: Optional[\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    204\u001b[39m ) -> InsertRecordSet:\n\u001b[32m    205\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m    Unpacks and normalizes the fields of an InsertRecordSet.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     base_record_set = \u001b[43mnormalize_base_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m InsertRecordSet(\n\u001b[32m    213\u001b[39m         ids=cast(IDs, maybe_cast_one_to_many(ids)),\n\u001b[32m    214\u001b[39m         metadatas=maybe_cast_one_to_many(metadatas),\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m         uris=base_record_set[\u001b[33m\"\u001b[39m\u001b[33muris\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    219\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\types.py:185\u001b[39m, in \u001b[36mnormalize_base_record_set\u001b[39m\u001b[34m(embeddings, documents, images, uris)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize_base_record_set\u001b[39m(\n\u001b[32m    175\u001b[39m     embeddings: Optional[Union[OneOrMany[Embedding], OneOrMany[PyEmbedding]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    176\u001b[39m     documents: Optional[OneOrMany[Document]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    177\u001b[39m     images: Optional[OneOrMany[Image]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    178\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    179\u001b[39m ) -> BaseRecordSet:\n\u001b[32m    180\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    Unpacks and normalizes the fields of a BaseRecordSet.\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BaseRecordSet(\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         embeddings=\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    186\u001b[39m         documents=maybe_cast_one_to_many(documents),\n\u001b[32m    187\u001b[39m         images=maybe_cast_one_to_many(images),\n\u001b[32m    188\u001b[39m         uris=maybe_cast_one_to_many(uris),\n\u001b[32m    189\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noliv\\phi-generation-repo-destination\\phi-generation\\venv_ftw\\Lib\\site-packages\\chromadb\\api\\types.py:82\u001b[39m, in \u001b[36mnormalize_embeddings\u001b[39m\u001b[34m(target)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     83\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected Embeddings to be non-empty list or numpy array, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m     )\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# One PyEmbedding\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target[\u001b[32m0\u001b[39m], (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target[\u001b[32m0\u001b[39m], \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: Expected Embeddings to be non-empty list or numpy array, got [] in upsert."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key= ''\n",
    "DATA_PATH = r''\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.md\")\n",
    "    documents = loader.load()\n",
    "    print(f\"\\n--- LOAD_DOCUMENTS ---\")\n",
    "    print(f\"Loaded {len(documents)} documents.\")\n",
    "    for i, doc in enumerate(documents):\n",
    "        print(f\"\\n--- Document {i + 1} ---\")\n",
    "        print(f\"Source: {doc.metadata['source']}\")\n",
    "        print(f\"Content Length: {len(doc.page_content)}\")\n",
    "        print(f\"Content Type: {type(doc.page_content)}\")\n",
    "        print(f\"Content:\\n{doc.page_content}\\n--- END OF CONTENT ---\\n\")\n",
    "    return documents\n",
    "\n",
    "def split_text(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"\\n--- SPLIT_TEXT ---\")\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\n--- Chunk {i + 1} ---\")\n",
    "        print(f\"Chunk Length: {len(chunk.page_content)}\")\n",
    "        print(f\"Chunk Content:\\n{chunk.page_content}\\n--- END OF CHUNK ---\\n\")\n",
    "    if len(chunks) > 10:\n",
    "        document = chunks[10]\n",
    "        print(f\"\\n--- Chunk 11 Details ---\")\n",
    "        print(f\"Content: {document.page_content}\")\n",
    "        print(f\"Metadata: {document.metadata}\")\n",
    "    else:\n",
    "        print(\"chunks list does not have 11 elements\")\n",
    "    return chunks\n",
    "\n",
    "def save_to_chroma(chunks):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "    vector_store = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)\n",
    "    vector_store.persist()\n",
    "    print(f\"\\n--- SAVE_TO_CHROMA ---\")\n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "\n",
    "def generate_data_store():\n",
    "    print(\"\\n--- GENERATE_DATA_STORE ---\")\n",
    "    documents = load_documents()\n",
    "    chunks = split_text(documents)\n",
    "    save_to_chroma(chunks)\n",
    "\n",
    "def main():\n",
    "    print(\"\\n--- MAIN ---\")\n",
    "    generate_data_store()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ftw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
